{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 自然言語処理における前処理\n",
    "* 機械学習モデルに食わせる以前の前処理について\n",
    "* このプロセスでは、文書を構成する文字列をどう決定づけるべきかについての意思決定が含まれる\n",
    "\n",
    "参考\n",
    "* http://haya14busa.com/python-nltk-natural-language-processing/\n",
    "* 情報検索の基礎\n",
    "    + https://nlp.stanford.edu/IR-book/html/htmledition/irbook.html\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# package"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## nltk\n",
    "* 定番ライブラリ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in /Users/seniorius/.pyenv/versions/anaconda3-4.4.0/lib/python3.6/site-packages\r\n",
      "Requirement already satisfied: six in /Users/seniorius/.pyenv/versions/anaconda3-4.4.0/lib/python3.6/site-packages (from nltk)\r\n"
     ]
    }
   ],
   "source": [
    "! pip install nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## see\n",
    "* オブジェクトが反応できる関数を列挙するライブラリ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: see in /Users/seniorius/.pyenv/versions/anaconda3-4.4.0/lib/python3.6/site-packages\r\n"
     ]
    }
   ],
   "source": [
    "! pip install see"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "     ismodule               help()                 .ISRIStemmer()\n",
       "     .LancasterStemmer()    .PorterStemmer()       .RSLPStemmer()\n",
       "     .RegexpStemmer()       .SnowballStemmer()     .StemmerI()\n",
       "     .WordNetLemmatizer()                          .api\n",
       "     .isri                  .lancaster             .porter\n",
       "     .regexp                .rslp                  .snowball\n",
       "     .util                  .wordnet"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "see(stem)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk import stem\n",
    "from nltk import tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from see import see"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## トークナイゼーション\n",
    "* 「なにがtokenか」は有用な議論だが、省略"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hello', 'world', '!']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenize.word_tokenize(\"hello world!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ストップワード\n",
    "* ありふれた語彙を落とす"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i', 'me', 'my', 'myself', 'we']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopset = set(stopwords.words('english'))\n",
    "stopwords.words('english')[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ステミング\n",
    "* token normalizationのための手法のひとつ\n",
    "    + token normalization: 文字列のうえでは多少の相違があるものを、一致させる処理\n",
    "* ステミングとレンマ処理\n",
    "    + ある語の屈折形や派生的な関連形を，共 通基盤系に帰着させること\n",
    "* nltk\n",
    "    + case-folding つまり `word.lower()` が自動でかかる\n",
    "    * ステミング方法がいくつかある\n",
    "        * Porter, Snowball, Lancaster だけ把握しておけば良さそう？\n",
    "        * http://blog.csdn.net/you1314520me/article/details/54970983\n",
    "    * WordNetLemmatizer というものも\n",
    "        * Lemmatize, レンマ処理: 見出語化する\n",
    "        * https://stackoverflow.com/questions/25534214/nltk-wordnet-lemmatizer-shouldnt-it-lemmatize-all-inflections-of-a-word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dialog'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmer = stem.LancasterStemmer()\n",
    "stemmer.stem('dialogue')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "まずトークナイゼーションし、ストップワードと短すぎる語を弾いたのち、ステミング処理をかける"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s = 'He grinned and said, \"I make lots of money.  On weekdays I receive an average of 50 orders a day from all over the globe via the Internet.\"'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['grin',\n",
       " 'said',\n",
       " 'mak',\n",
       " 'lot',\n",
       " 'money',\n",
       " 'weekday',\n",
       " 'receiv',\n",
       " 'av',\n",
       " 'ord',\n",
       " 'day',\n",
       " 'glob',\n",
       " 'via',\n",
       " 'internet']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[ stemmer.stem(w) \n",
    "     for w in tokenize.word_tokenize(s)\n",
    "     if w not in stopset and len(w) >= 3  ]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
